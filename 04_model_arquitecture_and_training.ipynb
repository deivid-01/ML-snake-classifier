{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://github.com/deivid-01/Snakes-Classifier/blob/main/04_model_arquitecture_and_training.ipynb\" target=\"_parent\\\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLj9TpczITy9",
    "tags": []
   },
   "source": [
    "# Model arquitecture and training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7irW4YyfLMM2"
   },
   "source": [
    "About:\n",
    "- This notebook focus on train and validate machine learning model.\n",
    "---\n",
    "David Andr√©s Torres Betancour <br/>\n",
    "Computer Engineering  Student <br/>\n",
    "University of Antioquia <br/>\n",
    "davida.torres@udea.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwTmy6SpJP1I"
   },
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0fFAqu659xSp",
    "outputId": "1e1b5eef-ee4f-4343-8b17-78f127cd7066"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow_hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (3.17.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "!pip install --upgrade tensorflow_hub\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.layers import Flatten, Dense,Dropout\n",
    "from tensorflow.keras.models  import Model,load_model\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications import vgg16\n",
    "from tensorflow.keras.applications import VGG16 # Wtf ?\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from google.colab import drive,files\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0seoI_clkGrL"
   },
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PUsnxgM4CNu"
   },
   "source": [
    "### Kaggle Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Eugra7qpkIzR"
   },
   "outputs": [],
   "source": [
    "def loadCredentials():\n",
    "  !rm kaggle.json\n",
    "  print(\"Upload kaggle.json file with credentials | IMPORTANT: Filename must be:kaggle.json\\n\")\n",
    "  files.upload() #Upload file\n",
    "  os.environ['KAGGLE_CONFIG_DIR'] = '/content' #Setup folder\n",
    "  ! chmod 600 /content/kaggle.json  #Hide kaggle.json\n",
    "\n",
    "def fetchDataSetFromKaggle():\n",
    "  loadCredentials()\n",
    "  ! kaggle datasets download -d deividt/snake-breeds #Download dataset\n",
    "  ! unzip \\*.zip && rm *.zip #Unzip downloaded file and delete zip\n",
    "  print(\"Loaded completed\")\n",
    "def fetchModelsFromKaggle():\n",
    "  ! kaggle datasets download -d deividt/snake-classifier-pretrainedmodels #Download dataset\n",
    "  ! unzip \\*.zip && rm *.zip #Unzip downloaded file and delete zip\n",
    "\n",
    "def kaggle_createDataset(public=False):\n",
    "  if public: \n",
    "    !kaggle datasets create -p  /content/model -u\n",
    "  else: \n",
    "    !kaggle datasets create -p  /content/model\n",
    "\n",
    "def kaggle_updateDataset(commit_message='Updating files'):\n",
    "   !kaggle datasets version -p /content/model/ -m commit_message\n",
    "\n",
    "def kaggle_setConfig(dataset_title=\"testing\"):\n",
    "\n",
    "  fileName=\"data/dataset-metadata.json\"\n",
    "  !kaggle datasets init -p  /content/model/\n",
    "  addTitle2JSON(fileName,dataset_title)\n",
    "\n",
    "\n",
    "def kaggle_saveModel():\n",
    "  \n",
    "  res = input(\"Do you want upload model  in  your kaggle Account? [y/n] \")\n",
    "  \n",
    "  if  res.lower()!=\"y\" :\n",
    "    return print(\"Upload canceled\")\n",
    "\n",
    "  res = readOption( msg = \"Create new dataset for saving models[1] or update old one[2]? [1/2]\")\n",
    "  \n",
    "  dataset_title = input(\"Enter dataset name: \")\n",
    "  assert len(res)>0 , \"Invalid length \"\n",
    "\n",
    "  kaggle_setConfig(dataset_title)\n",
    "\n",
    "  if res==\"1\": #Create new dataset\n",
    "    res = readOption( msg = \"Create dataset Private[1] or Public [2]? [1/2]\" )\n",
    "    public_dataset = True if int(res)==2 else False\n",
    "    kaggle_createDataset(public_dataset)\n",
    "  elif res==\"2\": #Update dataset\n",
    "    commit_msg = input (\"Enter commit message (Ex. 'version 1.4') : \")\n",
    "    kaggle_updateDataset(commit_msg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXCcOK-24E9I"
   },
   "source": [
    "### Model Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ofw-k7E4Man"
   },
   "outputs": [],
   "source": [
    "def loadModel(name):\n",
    "  try:\n",
    "    return load_model(name+'.h5')\n",
    "  except:\n",
    "    print(\"Model not found\")\n",
    "  \n",
    "\n",
    "def fetchModel():\n",
    "  print(\"Loading models from Kaggle\")\n",
    "  fetchModelsFromKaggle()\n",
    "  print(\"Models loaded\")\n",
    "  print(\"---------------------------------\")\n",
    "  model_name = input (\"\\nEnter model name: ( Ex: model_a ) \")\n",
    "  print(\"Searching model...\")\n",
    "  m = loadModel(model_name)\n",
    "  print(\"Model \"+model_name+\" loaded successfully\")\n",
    "  return m\n",
    "\n",
    "def getModel():\n",
    "\n",
    "  res = readOption(\" Create new model [1] or load pre-trained model from Kaggle [2]  [1/2] \")\n",
    "\n",
    "  if res =='1':\n",
    "    model_name = input(\" Set  model name: (Ex. model_A) \")\n",
    "    model = createModel( name= model_name ,num_breeds = 10 )\n",
    "    print(\"New model created\") \n",
    "  else:\n",
    "    loadCredentials()\n",
    "    model = fetchModel();\n",
    "  return model\n",
    "\n",
    "def model2TFLite(model):\n",
    "  converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "  tfmodel = converter.convert()\n",
    "  open(model.name+'.tflite','wb').write(tfmodel)\n",
    "  print(\"Model successfully convert to .tflite\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NV6MPr7R4OVA"
   },
   "source": [
    "### Extra Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BNqZSpmt4R7-"
   },
   "outputs": [],
   "source": [
    "def readOption(msg):\n",
    "\n",
    "  res = input(msg)\n",
    "  assert res=='1' or res=='2',\"Invalid option\"\n",
    "  return res\n",
    "\n",
    "def decode_breedID(idx):\n",
    "  df_decode = pd.read_csv('decode_breed.csv')\n",
    "  breed_encode = df_decode['breed_encode']\n",
    "  return df_decode.loc[breed_encode == idx]['breed'].tolist()[0]\n",
    "\n",
    "def custom_preprocess_input(x):\n",
    "\n",
    "\n",
    "  if not issubclass(x.dtype.type, np.floating):\n",
    "    x = x.astype('float32', copy=False)\n",
    "  print(x.dtype.type)\n",
    "\n",
    "      # 'RGB'->'BGR'\n",
    " # x = x[..., ::-1]\n",
    "  mean = [103.939, 116.779, 123.68]\n",
    "  # Zero-center by mean pixel\n",
    "  x[..., 0] -= mean[0]\n",
    "  x[..., 1] -= mean[1]\n",
    "  x[..., 2] -= mean[2]\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvEW2XFL6lai"
   },
   "source": [
    "### Training Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttJ8x1Gj6ncD"
   },
   "outputs": [],
   "source": [
    "def train(model,x_train,y_train,x_test,y_test , batch_size, epochs, model_name=\"\"):\n",
    "    model.fit(x_train, y_train, epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(x_test, y_test))\n",
    "    metrics = model.evaluate(x_test, y_test)\n",
    "    return {k:v for k,v in zip (model.metrics_names, metrics)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_K-R-ClGS2j"
   },
   "source": [
    "### File Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6lGv4PiGUYE"
   },
   "outputs": [],
   "source": [
    "def addTitle2JSON(fileName,dataset_title):\n",
    "    data = readFile(fileName)\n",
    "    data = addTitle2Data(data,dataset_title)\n",
    "    writeFile(fileName,data)\n",
    "    \n",
    "def writeFile(fileName,data):\n",
    "  with open(fileName,'w') as json_file:\n",
    "      # Guardar la informacion\n",
    "      json.dump(data,json_file)\n",
    "      print(\"File \"+fileName+\" updated\")\n",
    "\n",
    "def readFile(fileName):\n",
    "  with open(fileName, \"r\") as json_file: \n",
    "     return json.load(json_file)\n",
    "\n",
    "def addTitle2Data(data,title):\n",
    "  data['id'] = data['id'].split('/')[0]+'/'+title\n",
    "  data['title'] = title\n",
    "  return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzaK32JPKN2i"
   },
   "source": [
    "## Convolutional network arquitecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XX_H1OitKRa"
   },
   "source": [
    "- Using VGG16 Arquitecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "-78on5b8s5sB"
   },
   "outputs": [],
   "source": [
    "#Custom model\n",
    "def createModel(num_breeds,name=\"model\", ) :\n",
    "\n",
    "  vgg= VGG16( \n",
    "      input_shape= (224,224,3), \n",
    "      weights='imagenet',\n",
    "      include_top=False\n",
    "      )\n",
    "\n",
    "  #vgg.summary()\n",
    "  custom_model=vgg\n",
    "\n",
    "  for layer in custom_model.layers:\n",
    "    layer.trainable = False\n",
    "      \n",
    "  last_layer = Flatten()(custom_model.output)\n",
    "  last_layer = Dense(128, activation='relu', name='full_connected_1')(last_layer)\n",
    "  last_layer = Dense(128, activation='relu', name='full_connected_2')(last_layer)\n",
    "  out = Dense(num_breeds, activation='softmax', name='output')(last_layer)\n",
    "  custom_model = Model(custom_model.input, out,name=name)\n",
    "\n",
    "  \n",
    "  opt = Adam(lr=0.001) #Stochastic gradient descent\n",
    "  custom_model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  return custom_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJlXtxzf49zH"
   },
   "source": [
    "- Create a new model or load pre-trained model from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XlUboEsAF5dN"
   },
   "outputs": [],
   "source": [
    "model = getModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqzALibl5YP7"
   },
   "source": [
    "- Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8THxTrt5X1y"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSrJdh1-HhJn"
   },
   "source": [
    "## Training and validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jfSfnP_5ri2"
   },
   "source": [
    "- Fetch dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBxLhiex6Atl"
   },
   "outputs": [],
   "source": [
    "fetchDataSetFromKaggle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wYkoPG6v6BD9"
   },
   "source": [
    "- Training and validate just certain amout of groups because of RAM limits\n",
    "\n",
    "In this case is training just with eight groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qo6iFOE1HjSc",
    "outputId": "92a51658-8cf2-4b22-8cfb-17b497465348"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: 1\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 47s 220ms/step - loss: 7.5805 - accuracy: 0.2200 - val_loss: 3.8831 - val_accuracy: 0.2700\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 8s 154ms/step - loss: 1.7991 - accuracy: 0.6006 - val_loss: 3.7275 - val_accuracy: 0.3625\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 8s 155ms/step - loss: 0.5854 - accuracy: 0.8263 - val_loss: 3.8327 - val_accuracy: 0.3875\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 8s 156ms/step - loss: 0.2718 - accuracy: 0.9319 - val_loss: 4.3198 - val_accuracy: 0.3875\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.1061 - accuracy: 0.9787 - val_loss: 4.3014 - val_accuracy: 0.3775\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 8s 163ms/step - loss: 0.0311 - accuracy: 0.9969 - val_loss: 4.2251 - val_accuracy: 0.3825\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 8s 165ms/step - loss: 0.0175 - accuracy: 0.9987 - val_loss: 4.1393 - val_accuracy: 0.3875\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 4.1845 - val_accuracy: 0.4025\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 8s 170ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 4.2325 - val_accuracy: 0.3900\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 9s 174ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.2689 - val_accuracy: 0.3925\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 4.2689 - accuracy: 0.3925\n",
      "Group: 2\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 8s 168ms/step - loss: 1.3192 - accuracy: 0.7950 - val_loss: 2.3589 - val_accuracy: 0.6450\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 9s 172ms/step - loss: 1.0597 - accuracy: 0.7919 - val_loss: 2.2342 - val_accuracy: 0.6275\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 9s 177ms/step - loss: 0.6540 - accuracy: 0.8694 - val_loss: 2.2552 - val_accuracy: 0.6525\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 9s 179ms/step - loss: 0.2752 - accuracy: 0.9300 - val_loss: 2.5829 - val_accuracy: 0.6350\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 9s 176ms/step - loss: 0.2162 - accuracy: 0.9588 - val_loss: 2.3438 - val_accuracy: 0.6525\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 9s 172ms/step - loss: 0.1648 - accuracy: 0.9669 - val_loss: 2.8346 - val_accuracy: 0.6550\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 8s 169ms/step - loss: 0.0589 - accuracy: 0.9856 - val_loss: 2.5069 - val_accuracy: 0.6750\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.0445 - accuracy: 0.9912 - val_loss: 2.9972 - val_accuracy: 0.6250\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.0573 - accuracy: 0.9937 - val_loss: 2.7304 - val_accuracy: 0.6750\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.1387 - accuracy: 0.9775 - val_loss: 3.6773 - val_accuracy: 0.6100\n",
      "13/13 [==============================] - 2s 125ms/step - loss: 3.6773 - accuracy: 0.6100\n",
      "Group: 3\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 8s 168ms/step - loss: 0.9394 - accuracy: 0.8894 - val_loss: 0.8426 - val_accuracy: 0.8725\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 9s 174ms/step - loss: 0.4939 - accuracy: 0.9156 - val_loss: 0.8914 - val_accuracy: 0.8650\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 9s 178ms/step - loss: 0.1515 - accuracy: 0.9625 - val_loss: 1.2577 - val_accuracy: 0.8475\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 9s 178ms/step - loss: 0.0966 - accuracy: 0.9812 - val_loss: 0.8677 - val_accuracy: 0.8850\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 9s 176ms/step - loss: 0.0636 - accuracy: 0.9894 - val_loss: 1.0874 - val_accuracy: 0.8625\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 9s 172ms/step - loss: 0.0698 - accuracy: 0.9875 - val_loss: 1.6276 - val_accuracy: 0.8425\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 8s 169ms/step - loss: 0.1923 - accuracy: 0.9712 - val_loss: 1.3283 - val_accuracy: 0.8325\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.0745 - accuracy: 0.9844 - val_loss: 1.5384 - val_accuracy: 0.8375\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.1172 - accuracy: 0.9794 - val_loss: 1.7132 - val_accuracy: 0.8125\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 8s 168ms/step - loss: 0.1212 - accuracy: 0.9775 - val_loss: 1.4250 - val_accuracy: 0.8200\n",
      "13/13 [==============================] - 2s 127ms/step - loss: 1.4250 - accuracy: 0.8200\n",
      "Group: 4\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 8s 168ms/step - loss: 0.4798 - accuracy: 0.9350 - val_loss: 0.8113 - val_accuracy: 0.9050\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 9s 175ms/step - loss: 0.4061 - accuracy: 0.9381 - val_loss: 0.6635 - val_accuracy: 0.9050\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 9s 179ms/step - loss: 0.3662 - accuracy: 0.9519 - val_loss: 0.9355 - val_accuracy: 0.8950\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 9s 179ms/step - loss: 0.1764 - accuracy: 0.9613 - val_loss: 0.9413 - val_accuracy: 0.8825\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 9s 176ms/step - loss: 0.0736 - accuracy: 0.9825 - val_loss: 1.0151 - val_accuracy: 0.9075\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 8s 171ms/step - loss: 0.0694 - accuracy: 0.9881 - val_loss: 1.1640 - val_accuracy: 0.8925\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 8s 169ms/step - loss: 0.0687 - accuracy: 0.9887 - val_loss: 1.0396 - val_accuracy: 0.9025\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.0278 - accuracy: 0.9962 - val_loss: 1.0641 - val_accuracy: 0.8900\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 1.0321 - val_accuracy: 0.8900\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.9424 - val_accuracy: 0.8625\n",
      "13/13 [==============================] - 2s 128ms/step - loss: 0.9424 - accuracy: 0.8625\n",
      "Group: 5\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.2758 - accuracy: 0.9650 - val_loss: 0.3993 - val_accuracy: 0.9800\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 9s 173ms/step - loss: 0.2292 - accuracy: 0.9606 - val_loss: 0.7165 - val_accuracy: 0.9175\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 9s 178ms/step - loss: 0.2534 - accuracy: 0.9588 - val_loss: 0.4864 - val_accuracy: 0.9525\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 9s 179ms/step - loss: 0.0964 - accuracy: 0.9831 - val_loss: 0.5071 - val_accuracy: 0.9625\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 9s 177ms/step - loss: 0.0277 - accuracy: 0.9912 - val_loss: 0.5955 - val_accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 9s 173ms/step - loss: 0.0412 - accuracy: 0.9912 - val_loss: 0.4635 - val_accuracy: 0.9600\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 8s 170ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.4292 - val_accuracy: 0.9675\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 8s 168ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.4486 - val_accuracy: 0.9625\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 2.0731e-04 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9650\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 5.3606e-05 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.9650\n",
      "13/13 [==============================] - 2s 129ms/step - loss: 0.4539 - accuracy: 0.9650\n",
      "Group: 6\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.1370 - accuracy: 0.9881 - val_loss: 0.1539 - val_accuracy: 0.9600\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 9s 173ms/step - loss: 0.0369 - accuracy: 0.9900 - val_loss: 0.2724 - val_accuracy: 0.9900\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 9s 177ms/step - loss: 0.1009 - accuracy: 0.9819 - val_loss: 0.5235 - val_accuracy: 0.9750\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 9s 179ms/step - loss: 0.3930 - accuracy: 0.9563 - val_loss: 0.8415 - val_accuracy: 0.9250\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 9s 178ms/step - loss: 0.5122 - accuracy: 0.9581 - val_loss: 1.0786 - val_accuracy: 0.9175\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 9s 172ms/step - loss: 0.2868 - accuracy: 0.9625 - val_loss: 1.0574 - val_accuracy: 0.8925\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 8s 170ms/step - loss: 0.1384 - accuracy: 0.9812 - val_loss: 0.8106 - val_accuracy: 0.9300\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 8s 168ms/step - loss: 0.0445 - accuracy: 0.9900 - val_loss: 0.9067 - val_accuracy: 0.9425\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.1088 - accuracy: 0.9881 - val_loss: 1.0320 - val_accuracy: 0.9400\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.1132 - accuracy: 0.9937 - val_loss: 1.0180 - val_accuracy: 0.8825\n",
      "13/13 [==============================] - 2s 127ms/step - loss: 1.0180 - accuracy: 0.8825\n",
      "Group: 7\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 8s 168ms/step - loss: 0.3448 - accuracy: 0.9681 - val_loss: 0.1809 - val_accuracy: 0.9725\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 9s 173ms/step - loss: 0.3542 - accuracy: 0.9769 - val_loss: 0.4747 - val_accuracy: 0.9525\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 9s 178ms/step - loss: 0.1891 - accuracy: 0.9781 - val_loss: 0.2763 - val_accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 9s 179ms/step - loss: 0.2004 - accuracy: 0.9775 - val_loss: 0.4535 - val_accuracy: 0.9450\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 9s 176ms/step - loss: 0.0727 - accuracy: 0.9862 - val_loss: 0.6188 - val_accuracy: 0.9425\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 9s 172ms/step - loss: 0.1383 - accuracy: 0.9844 - val_loss: 0.6225 - val_accuracy: 0.9325\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 8s 169ms/step - loss: 0.1275 - accuracy: 0.9894 - val_loss: 0.5613 - val_accuracy: 0.9425\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.0581 - accuracy: 0.9906 - val_loss: 0.6095 - val_accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 8s 168ms/step - loss: 0.0414 - accuracy: 0.9925 - val_loss: 0.6840 - val_accuracy: 0.9175\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 8s 167ms/step - loss: 0.0932 - accuracy: 0.9931 - val_loss: 1.4348 - val_accuracy: 0.9200\n",
      "13/13 [==============================] - 2s 128ms/step - loss: 1.4348 - accuracy: 0.9200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(1,8):\n",
    "\n",
    "    destination_filepath = BASE_PATH+'/v6/batchs/'+'group_'+str(i)+'.h5'\n",
    "    with h5py.File(destination_filepath, \"r\") as f:\n",
    "        \n",
    "        print(\"Group:\",i)\n",
    "        \n",
    "        x = f[\"input_data\"][:]\n",
    "        y = f[\"input_labels\"][:]\n",
    "        x=x.reshape(x.shape[0],224,224,3)\n",
    "        x=preprocess_input(x*255)\n",
    "        \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.20)\n",
    "    \n",
    "    #Displaying information just for the first group\n",
    "    if i ==1 :\n",
    "      print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "      print(\"\\nDistribution of train classes\")\n",
    "      print(pd.Series(y_train).value_counts())\n",
    "      print(\"\\nDistribution of test classes\")\n",
    "      print(pd.Series(y_test).value_counts())\n",
    "\n",
    "    train(model,x_train,y_train,x_test,y_test , batch_size=32, epochs=10, model_name=\"modelA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwIDlMpM7uNH"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtPo4WTHHrU5"
   },
   "source": [
    "-Testing with images from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VyieXRZN7wqh"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Set random image\n",
    "img = cv2.imread('agkistrodon-contortrix.png')\n",
    "\n",
    "img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC) #Resize\n",
    "plt.imshow(img) #Display Image\n",
    "#img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "img= img.reshape(1,224,224,3)\n",
    "img = custom_preprocess_input(img)\n",
    "yhat = model.predict(img)\n",
    "\n",
    "index = yhat.argmax()\n",
    "print(decode_breedID( index ))\n",
    "np.max(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjsixfxdHfXk"
   },
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuGYWhSx7LwP"
   },
   "source": [
    "- Local save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FBb4yC5VFqQ_"
   },
   "outputs": [],
   "source": [
    "#Saving model\n",
    "!mkdir model\n",
    "model.save('model/'model.name+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFUhJOOZ7i9p"
   },
   "source": [
    "- Saving model in Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JgUx2bWac6-",
    "outputId": "9d3965c2-7cd2-464c-d26d-4a2faf0fc0aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want upload model  in  your kaggle Account? [y/n] n\n",
      "Upload canceled\n"
     ]
    }
   ],
   "source": [
    "kaggle_saveModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swAVSm2k7893"
   },
   "source": [
    "#Convert model to Tensorflow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uIlKCA_GB3E5",
    "outputId": "9cae151c-4604-4e49-dee8-25bdf6f2cf29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxunj5ubq/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxunj5ubq/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71785940"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2TFLite(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "CmweXhcOJni3"
   ],
   "name": "04 - model arquitecture and training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
